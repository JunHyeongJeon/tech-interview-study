## 3. Operating System
**:book: Contents**

- [OS란 무엇이며, 핵심 기능은?](#OS개념과-핵심-기능)
- [부팅이 되는 과정을 설명하시오.](#부팅이-되는-과정)
- [프로세스의 5가지 상태에 대해 설명하시오.](#프로세스의-5가지-상태)
- [메모리 계층 구조를 설명하시오.](#메모리-계층-구조)
- [캐시와 버퍼의 차이점은?](#캐시와-버퍼의-차이점)

* [세마포어와 뮤텍스란? 차이점은 무엇인가?](#세마포어와 뮤텍스란?-차이점은-무엇인가?)			
* [메모리 단편화, 페이징, 세그멘테이션](#메모리-단편화,-페이징,-세그멘테이션)			
* [선점스케줄링과 비선점스케줄링, 해당하는 알고리즘 한개씩](#선점스케줄링과-비선점스케줄링,-해당하는-알고리즘-한개씩)				
* [문맥교환이란?](#문맥교환이란?)			
* [PCB란?](#PCB란?)


* [가상메모리란?](#가상메모리란?)
* [Deadlock이란?](#Deadlock이란?)
* [프로세스의 메모리구조?](#프로세스의-메모리구조?)
* [thrashing이란?](#thrashing이란?)
* [프로세스간 통신하는 방법은?](#프로세스간-통신하는-방법은?)


* 멀티프로세싱, 멀티프로그래밍, 멀티스레딩, 멀티태스킹
* 톰캣은 멀티 프로세스인가 멀티 스레드인가
* 아파치는 멀티 프로세스인가 멀티 스레드인가
* 동기, 비동기, 블로킹, 넌블로킹 차이
* 스레드와 프로세스의 차이
* Thread 가 3개 생성 되었을 때 t1, t2, t3의 순서가 보장 되는 코드를 짜 보세요.

---

## OS개념과 핵심 기능
**운영체제란**
H/W와 S/W 사이에서 둘을 효율적으로 운영하고 관리하여
사용자가 컴퓨터를 편리하게 사용할수 있도록 하는 프로그램

**운영체제 기능**
1. 자원관리
- 컴퓨터 시스템을 구성하는 cpu, 기억장치, 주변장치, data등 컴퓨터 자원을 관리한다

2. 프로세스 관리
- 프로세스와 쓰레드 스케줄링, 프로세스 생성과 제거, 프로세스 시작, 정지, 재수행
- 프로세스 동기화 및 통신, 주기억 장치 관리를 위해 주기억장치 관리자와 협력

3. 기억장치 관리
- 메모리 상태 추적, 메모리 할당 및 회수, 가상기억장치 및 페이징 장치 관리, 장치 관리자 또는 파일 관리자와 협력

4. 입출력 장치 관리
- 입출력 장시의 스케줄 관리, 각종 주변장치의 스케줄링 및 관리

5. 파일 관리
- 파일 생성과 삭제, 변경 유지들의 관리
- 정보의 위치, 사용여부와 상태 등을 추적 관리

> <https://flearning-blog.tistory.com/16>

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 부팅이 되는 과정
> <https://neos518.tistory.com/113>

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 프로세스의 5가지 상태
![프로세스 상태](https://user-images.githubusercontent.com/55946791/80938240-559b8600-8e13-11ea-9176-a121491a0fb3.jpg)
1. 생성 : 프로세스 생성 상태 , pcb를 할당받은 상태
2. 실행 : 프로세스가 cpu에 할당되어 실행 중인 상태
3. 준비 : 프로세스가 cpu에 할당되기를 기다리는 상태
4. 대기 : 보류(block)라고도 하며, 프로세스가 입출력이나 이벤트릴 기다리는 상태
5. 종료 : 프로세스 종료 상태

> <https://rebas.kr/852>

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 메모리 계층 구조
![메모리 계층](https://user-images.githubusercontent.com/55946791/80938438-128de280-8e14-11ea-8207-95cb98d94303.jpg)

**메모리 종류**
1. Main 메모리 : 램 (RAM)
2. Register : cpu안에 내장되어 있어 연산을 위한 저장소 제공
3. Cache : cpu와 RAM사이에서 중간 저장소 역할
4. Hard Disk와 이외 장치 : 하드디스크, I/O장치 등
(* CPU와 거리가 가까울수록, 빠르고 용량이 작다. 멀수록, 느리고 용량이 크다)

**데이터 이동**
- 프로그램의 실행을 위해 하드디스크에 있는 내용은 메인 메모리로 이동한다
- 메인 메모리에 있는 일부 데이터도 실행을 위해 L2캐시로 이동한다
- L2캐시에 있는 데이터 일부는 L1캐시로 이동한다
- L1캐시에 있는 데이터 중 연산이 필요한 데이터는 레지스터로 이동한다.

> <https://dakuo.tistory.com/126>

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 캐시와 버퍼의 차이점

**캐시**
- 이전에 접근한 데이터를 빠르게 접근하기 위해 임시로 저장
- 교체 알고리즘에 따라 삭제될수도 안될수도있다
- 캐시는 어떤 원리로 저장되나요? __지역성__ / (시간, 공간)
	- 한번 참조되면 가까운 미래에 또 사용될수있다
	- 참조된 메모리에 가까운 곳에 있는 데이터가 또 사용될수있다

**버퍼**
- 전송전에 임시로 저장
- 미리 출력할것을 버퍼에 담아서 성능 빠르게
- 사용후에 바로 삭제 된다


> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)



## 세마포어와 뮤텍스란? 차이점은 무엇인가?

**세마포어와 뮤텍스 정의**
- 여러 프로세스나 쓰레드가 __공유 자원에 접근하는 것을 제어하기__ 위한 방법
- __병행 처리를 위한 프로세스 동기화 기법__

**세마포어**
- 세마포어 변수, wait()함수, signal()함수가 있다.
- 세마포어 변수 : 공유 가능한 자원의 수
- wait() : 세마포어 값을 감소 시킨다. 음수가되면 호출한 프로세스는 블록된다.
- signal() : 실행되던 프로세스가 종료되어, 세마포어 값을 증가시킨다. 만약 값이 0이거나 음수면, swmWait연산에 의해 블록된 프로세스를 wake_up한다
<br>
- 세마포어 종류 : binary 세마포어(세마포어가 0또는1만허용), counting 세마포어(0또는1이상의수를 가질수있다)

**뮤텍스**
- 초기값을 1과0으로 가진다
- 임계구역에 들어갈때 락(lock)을 걸어 다른 프로세스(or 쓰레드)가 접근하지 못하도록하고
- 임계구역에서 나올때 해당 락을 해제(unlock)한다.

**뮤텍스와 세마포어의 차이**
- 세마포어는 공유 자원에 __세마포어의 변수만큼 프로세스(or 쓰레드)가__ 접근할 수 있다
- 반면에 뮤텍스는 __오직 1개만의 프로세스(or 쓰레드)만 접근 가능
<br>
- 현재 수행중인 프로세스가 아닌 __다른 프로세스가 세마포어 해제__ 가능
- 뮤텍스는 __락(lock)을 획득한 프로세스가 반드시 그 락을 해제__ 해야 한다.

> [참고](https://velog.io/@conatuseus/OS-%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4%EC%99%80-%EB%AE%A4%ED%85%8D%EC%8A%A4)

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 메모리 단편화, 페이징, 세그멘테이션


- 세그멘테이션-가변적으로 자른다 / 장점,단점
- 페이지-고정된 크기로 자른다 / 장점, 단점
- 물리메모리- 프레임
- 가상메모리- 페이지

**메모리 단편화**
- 메모리의 공간이 작은 조각으로 나뉘어져서 __사용가능한 메모리가 충분히 존재하지만 할당(사용)이 불가능한 상태__

**외부 단편화**
- 메모리가 할당되고 해제되는 작업이 반복되면서 작은 메모리가 중간중간에 존재
- 이 때 중간에 생긴 사용하지 않은 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할수 없는 상황

**내부 단편화**
- __프로세스가 필요한 양보다 더 큰 메모리가 할당 되어서__ 프로세스에서 사용하는 메모리가 낭비되는 상황


**페이징 기법**
- 외부 단편화 해결, 내부 단편화 존재
- __가상메모리를__ 같은 크기의 블록으로 나눈것을 __페이지__ 라고한다.
- __물리메모리를__ 같은 크기의 블록으로 나눈것을 __프레임__ 이라고 한다.
<br>
- 방법
	- 프로세스를 페이지 단위로 나눈 뒤에, 사용하지 않는 영역을 보조기억장치에 적재한다. 이를 페이징 되었다고 하는데, 만약 이 페이징 된 영역에 접근해야 하면 페이징 폴트를 발생시킨 후 메모리에 적재시킨다(요구 페이징). 페이징된 정보는 페이징테이블에 저장된다.

- 장점
	- 연속적이지 않은 공간도 활용할수 있기 때문에 외부 단편화 문제를 해결 할 수 있다.
- 단점
	- 내부 단편화가 발생할 수 있다

**페이지 테이블이란 ?**
- 페이징 기법에서 사용되는 자료구조로서, __프로세스의 페이지 정보를 저장하고__ 있는 테이블이다.

**세그멘테이션 기법**
- 내부 단편화 해결, 외부 단편화 존재
- 가상메모리를 __서로 크기가 다른 논리적 단위인 세크멘트로 분할해서 메모리를 할당__ 하여 실제 메모리 주소로 변환을 하게 된다.
- 각 세그먼트는 __연속적인 공간에 저장__ 되어 있다.
- 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈공간을 찾아 할당하는 기법.

> [참고](https://jeong-pro.tistory.com/91)

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 선점스케줄링과 비선점스케줄링, 해당하는 알고리즘 한개씩

- 선점 알고리즘 : 어떤 프로세스가 CPU를 할당 받아 실행 중이더라도 OS가 CPU를 강제로 빼앗을 수 있다.

**비선점 알고리즘**
- FCF
- SJF(Shortest Job First, 실생 시간이 가장 짧은 작업부터)
- HRN(Highest Response Ratio Next, 최고 응답률 우선 스케줄링)

**선점 알고리즘**
- RR(Round Robin) : 할당받은 시간(타임 슬라이스)동안 작업 하다가 작업 미완료시 준비 큐의 맨뒤로 간다.
- SRT(Shortest Remaining Time) : SJF + RR 방식
  - 최소 잔류 시간 우선 스케줄링
  - 나은 시간이 적은 프로세스에 CPU를 먼저 할당
- 다단계 큐 스케줄링
  - 우선순위에 따라 준비 큐가 여러개
  - 상단의 큐에 잇는 모든 프로세스가 종료되야 다음 우선순위 큐의 작업이 시작된다.
- 다단계 피드백 큐 스케줄링
  - __우선순위가 낮은 프로세스에 불리한 다단계 큐 스케줄링__ 을 보완한 방식
  - CPU를 사용하고 난 프로세스는 원래 큐로 돌아가지않고, 우선순위가 하나 낮은 큐의 끝으로 들어간다.
  - 우선순위를 낮춤으로써, 다단계 큐에서 우선순위가 낮은 프로세스의 실해이 연기되는 문제를 완화한다.

**둘 다 가능**
- 우선순위 스케줄링
  - 프로세스는 중요도에 따라 우선순위를 갖는다.
  - 일정 시간마다 우선순위가 변하거나 고정되거나

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 문맥교환이란?
- CPU를 차지하던 프로세스가 나가고 새로운 프로세스를 받아들이는 작업을 말한다.
- 두 프로세스의 PCB를 교환 하는 작업
- 현재까지의 작업 상태를 저장하고 다음 작업에 필요한 각종 상태, 데이터를 읽어오는 작업
<br>
- 멀티 프로세스 환경에서 CPU 스케줄러가 인터럽트 발생 시 현재 프로세스의 상태를 PCB에 저장하고, 새로운 프로세스의 상태를 레지스터에 저장하는 것을 말함.
- 인터럽트의 종류 :
	- I/O Request : 입출력 요청
	- Time Slice Expired : CPU 사용시간 만료
	- Fork Child : 자식 프로세스 생성
	- Wait for interrupt : 인터럽트 처리 대기

- 컨텍스트 스위칭 시 CPU는 아무런 작업을 하지 못한다. 따라서 잦은 컨텍스트 스위칭은 성능 저하를 일으킴.

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## PCB란?
- __프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료구조__
- __각 프로세스가 생성될 때마다 고유의 PCB가__ 생성되고, 완료되면 제거된다.
<br>
- 프로세스는 CPU를 할당받아 작업을 처리하다가, CPU를 선점 당하게 되면 진행 중이던 작업 내용을 PCB에 저장하고 CPU를 반환한다.
- 이후에 다시 CPU를 할당받으면 PCB로 부터 진행이 끊겼던 부분에서 다시 작업을 실행한다
- 프로세스 식별자, 상태, PC(프로그램 카운터, 다음 실행할 명령의 주소 가르킴), 메모리 관리 정보 등을 가지고 있다.

> :arrow_double_up:[Top](#3-os)    :leftwards_arrow_with_hook:[Back](https://github.com/devham76/tech-interview-studyw#3-os)    :information_source:[Home](https://github.com/devham76/tech-intervie-studyw#tech-interview)

## 가상메모리란?
실제 시스템에 있는 물리적인 메모리의 크기에 상관 없이 가상 공간을 프로세스에게 제공합니다. 이런 가상 메모리는 프로세스 전체가 메모리에 적재되지 않아도 프로세스의 실행이 가능하도록 합니다.


> [참고](https://ko.wikipedia.org/wiki/%EA%B0%80%EC%83%81_%EB%A9%94%EB%AA%A8%EB%A6%AC)

> [참고](https://twinw.tistory.com/106?category=543743)

- 가상메모리 어떻게 구현하나요 ? - 페이징, 세크멘테이션

## Deadlock이란?

- 교착 상태란 두 개 이상의 작업이 서로 __상대방의 작업이 끝나기 만을 기다리고__ 있기 때문에 결과적으로 아무것도 완료되지 못하는 상태를 가리킨다


## Deadlock이란?

- 교착 상태란 두 개 이상의 작업이 서로 상대방의 작업이 끝나기 만을 기다리고 있기 때문에 결과적으로 아무것도 완료되지 못하는 상태를 가리킨다

- 멀티프로세스나 멀티쓰레드 환경에서 __여러 프로세스들이 한정된 자원을__ 사용하기 때문에 발생할 수 있다


**데드락 발생 조건**
- 모두 충족해야 발생

1. 상호배제
	- 자원은 한 번에 한 프로세스만이 사용할수 있다
2. 점유대기 (Hold and wait)
	- 자원을 할당받은 상태에서 다른 자원을 기다리는 상태
3. 비선점
	- 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 뺏을수 없다
4. 순환 대기 (Circular wait)
	- 점유와 대기를 하는 프로세스 간의 관계가 원을 이룬다.
	- 점유와 대기를 하는 프로세스들이 서로 방해하는 방향이 원을 이루면, 프로세스들이 서로 양보하지 않기 때문에 교착상태 발생

**데드락 처리 - 1.예방**
- 교착 상태 발생 조건 중 하나를 제거함으로써 해결
	1) 상호배제 부정 : 여러 개의 프로세스가 공유 자원 사용가능 (보호해야할 자원을 공유하기힘들다)
	2) 점유대기 부정 : 자원을 점유한상태에서 다른 자원 기다리지 못함. (전부 할당 or 아예할당x)
	3) 비선점 부정 : 자원을 빼앗을 수 있도록 만든다 (우선순위가 낮은 프로세스 기아현상)
	4) 순환대기 부정 : 모든 자원에 숫자를 부여하고 숫자가 큰 방향으로만 자원할당(번호 부여 방식 선정 어려움)
- 문제점 :
	- 자원을 보호하기 위해 1.상호배제, 3.비선점을 예방하기 어렵고
	- 2.점유대기, 4.순환대기는 프로세스 작업 방식을 제한하고 자원을 낭비한다

**데드락 처리 - 2.회피**
- 교착 상태가 발생하면 피하는 방법
- 교착 상태가 발생하지 않는 범위 내에서만 자원할당, 교착 상태 발생하는 범위에서 프로세스 대기
- 교착 상태 예방보다 좀 더 유연하다.

**은행원 알고리즘 (Banker’s Algorithm)**
- 은행이 대출 해주는 방식. 즉, 대출 금액이 대출 가능한 범위이면(안정 상태) 허용, 그렇지 않으면 거부.
- 안정 상태에 있으면 자원을 할당하고, 그렇지 않으면 다른 프로세스들이 자원을 해지할 때까지 대기함
<br>
- 최대 자원 : 자신이 사용할 자원의 최대수
- 할당 자원 : 할당된 자원수
- 기대 자원 : 최대자원 - 할당 자원
- 가용 자원 : 남은 자원의 수
<br>
- 문제점 :
	- 모든 프로세스가 __자신이 사용할 모든 자원을 미리 알기 어렵다__
	- 시스템의 전체 자원 수는 유동적이므로 전체 자원 수를 고정하기 어렵다
	- 자원 낭비 ; 실제로 교착상태가 발생하지 않았지만 발생할 것이라고 예상하여, _프로세스에 자원 할당하는 것에 제약_ 을 둔다.

**데드락 처리 - 3.탐지**
- os가 프로세스의 작업을 관찰하면서 데드락 발생 여부를 계속 주시

**타임아웃**
- __일정 시간 동안 작업이 진행되지 않은 프로세스를__ 데드락 발생한것으로 간주하여 처리
- 자원 할당 그래프를 이용하는것보다 쉽기 때문에 선호한다

**자원 할당 그래프**
- 자원할당 그래프를 통해 프로세스가 어떤 자원을 사용, 기다리는지 알 수 있다
- 장점 : 프로세스의 작업 방식을 제한하지 않으면서 교착상태를 정확하게 파악
- 단점 : 자원 할당 그래프를 유지, 갱신, 사이클 검수하면서 __오버헤드가 발생__
	- 추가 작업을 줄이기 위해 자원 할당시마다 사이클 검사X, 일정 시간마다 검사하는 방법도 있음



**데드락 처리 - 4.회복**
- 데드락 발생 시킨 프로세스 종료하거나 할당된 자원을 해제 하여 회복하는 것을 의미
1. 교착상태 발생시킨 프로세스 동시에 종료
2. 교착상태 발생시킨 프로세스 중 하나를 골라 순서대로 종료
	- 우선순위 낮은 프로세스 종료
	- 작업 시간 짧은 프로세스 종료
	- 자원을 많이 사용하는 프로세스 종료

> [참고](https://jwprogramming.tistory.com/12)
> [참고 - 쉽게 배우는 운영체제]

## 프로세스의 메모리구조?

![메모리 구조](https://user-images.githubusercontent.com/55946791/81517248-423d6d00-9375-11ea-9cfe-84f20b7b4740.jpg)
- 메모리 영역은 크게 두가지로 나눌 수 있는데 컴파일시 크기가 고정되는 code, data, bss 영역과 실행시 메모리가 할당되었다 반납되는 heap, stack영역으로 나눌 수 있다.


1. 메모리 할당이 고정되는 영역 (compile시 결정)

	* code영역
		- 실행 파일을 구성하는 명령어들이 올라가는 메모리 영역으로 함수, 제어문, 상수 등이 여기에 지정된다.

	* data 영역 & BSS
		- data 영역은 BSS와 함께 묶어서 데이터 영역으로 칭하기도 하는데 이는 전역변수와 static변수가 지정되는 영역이다.
		- 초기화 되지 않은 전역변수들은 BSS에 지정된다.
    - data :초기값 있는 전역밴수, 배열, static으로 선언된 변수
    - bss : 초기값 없는 전역변수, 배열, static으로 선언된 변수

2. 실행 중에 메모리를 할당하는 영역(할당과 반납이 이루어짐)
		- data 영역은 BSS와 함께 묶어서 데이터 영역으로 칭하기도 하는데 이는 전역변수와 Static변수가 지정되는 영역이다.
		- 초기화 되지 않은 전역변수들은 BSS에 지정된다.


2. 실행 중에 메모리를 할당하는 영역(할당과 반납이 이루어짐)

	* HEAP 영역
		- malloc(), calloc() 등으로 프로그래머가 자율적으로 메모리 크기를 할당할 수 있는 영역이다.
		- 위의 함수들은 free()함수로 할당된 영역을 반납해줘야하므로 동적할당 영역에 속한다.

	* STACK 영역
		- 지역변수가 할당되는 영역으로 함수가 호출되면 할당되었다 함수의 종료시 반납되는 영역이다.


**메모리 오버플로우**
- 위의 HEAP과 STACK영역은 사실 같은 공간을 공유한다.
- HEAP이 메모리 위쪽 주소부터 할당되면 STACK은 아래쪽 부터 할당되는 식이다.
- 그래서 각 영역이 상대 공간을 침범하는 일이 발생할 수 있는데 이를 각각 HEAP OVERFLOW, STACK OVERFLOW라고 칭한다.

![메모리 오버플로우](https://user-images.githubusercontent.com/55946791/81517246-410c4000-9375-11ea-8d4e-fc9bb40d0387.jpg)

> [참고](https://zapiro.tistory.com/entry/%ED%95%A8%EC%88%98%EC%99%80-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%98%81%EC%97%AD)

## thrashing이란?

- 가상메모리 크기 = 물리메모리 + 스왑영역 (하드디스크에 존재 or 멤리 관리자가 관리하는 영역)

**페이지 부재(페이지 폴트)**
- 프로세스가 페이지를 요청했을 때 그 페이지가 메모리에 없는 상황
![페이징 매칭](https://user-images.githubusercontent.com/55946791/81517925-613cfe80-9377-11ea-99e8-35dcce20fb79.jpg)
ex) 프로세스가 페이지 4를 요청 했을때, 페이지 테이블에 유효비트1, 주소 필드값 1 이므로 __메모리에 없고 스왑영역__ 에 있다. 이것을 페이지 부재라한다

- ex) 1,2,3 있을때 실제 메모리에 1,2 할당, 다음에 3할당하려면 빼고...반복

**Thrashing(쓰레싱)**
- 메모리에 __페이지 부재율이 높은것,__ 심각한 성능 저하를 초래
- 하드디스크의 입출력이 너무 많아져서 잦은 페이지 부재로 작업이 멈춘 것 같은 상태
- 재료를 창고->도마 or 도마->창고 옮기는 작업이 많아, 요리 못하는 상태

**스레싱과 물리 메모리 크기**
- __멀티프로그래밍 정도__ : 동시에 실행하는 프로그램의 수
- 멀티프로그래밍 정도가 높으면 스레싱 발생
- 메모리가 꽉차면,
	- cpu가 작업하는 시간  < 스왑영역으로 페이지 보내고, 새로운 페이지 가져오는 작업 시간
	- cpu가 작업할 수 없는 상태 --> __스레싱 발생 지점__
![멀티 프로그래밍 정도와 스레싱](https://user-images.githubusercontent.com/55946791/81518391-d9f08a80-9378-11ea-8a2c-196ae4ac0417.png)

**물리 메모리 크기와 작업 속도**
- 물리 메모리 용량을 512MB->4GB로 늘리면, 스레싱 발생 지점 늦춰져서 성능 향상
- 물리 메모리 용량을 4GB -> 16GB로 늘리면 ? (물리 메모리가 작업하는데 충분한 크기면) 크기를 늘려도 작업 속도에 영향 미치지 X
	- 식탁 크기의 도마 -> 방 크기의 도마로 바꾼다해서 요리 시간이 빨라지지 X


**스레싱과 프레임 할당**
- 남아 있는 프레임을 실행 중인 프로세스에 적절히 나눠주는 정책
- 프로세스에 너무 적은 프레임 할당시, 페이지 부재 빈번
- 너무 많은 프레임 할당시, 페이지 부재 少, 메모리 낭비
--> 각 프로세스가 필요로 하는 최소한의 프레임 갯수를 보장해줘야 한다.

- 정적할당
- 동적할당

> [참고](https://jwprogramming.tistory.com/56)
> [참고 - 쉽게 배우는 운영체제]

## 프로세스간 통신하는 방법은?

![프로세스간 통신](https://user-images.githubusercontent.com/55946791/81771876-237ada00-951f-11ea-8ef9-e12e862dd5e4.jpg)

프로세스간 통신(IPC, Inter Process Communication)

- 정의 :  하나의 컴퓨터 안에서 실행중인 서로 다른 프로세스 간 발생하는 통신
- 기능 : 의사 소통 기능 & 동기화를 보장해야 한다.
- 동기화 : 하나의 프로세스가 공유 데이터 값을 변경하는 동안 , 다른 프로세스는 그 데이터에 접근 x
- 종류 : 메시지 전달(message passing) & 공유 메모리(shared memory) / __공유 변수 사용 여부에__ 나뉜다

**1.메시지 전달**
- 특징 : ipc를 위해 __커널을 통해__ 메세지를 전달하는 방식으로 자원,데이터 주고받는다
- 장점 : 별도의 구축없이 커널을 이용하기 때문에 비교적 구현이 쉽다
- 단점 : 커널을 이용하기 때문에, __시스템 콜__이 필요하며 이로 인해 __오버헤드가__ 발생
- 종류 : __파이프, 메시지 큐, 소켓, 시그널 등__

**1-1.메시지 전달 모델 - 파이프**
- 특징 : 하나의 프로세스가 파이프를 통해 다른 프로세스로 메시지를 직접 전달
- 단점 : __단방향 통신__ , 따라서 2개의 프로세스 통신시, 2개 파이프 필요 -> 100개 프로세스 통신시, 100P2 = 9900개 필요하므로 __자원 낭비가 심하다__
- 종류 : 익명파이프, 네임드 파이프

**익명파이프**
- 사용에 제한이 있다.
	- 이름이 없기 때문에 __외부 프로세스에서 이 파이프 호출불가__
	- 부모, 자식 프로세스 간 통신시 사용

**네임드파이프**
- 이름이 있기 때문에 __외부 프로세스와 통신 가능__

**1-2.메시지 전달 모델 - 메시지 큐**
- 특징 : 고정 크키의 메시지를 연결 리스트를 통해 통신하는 방식
- 메시지 단위의 통신, 메시지 큐id를 통해 통신

**1-3.메시지 전달 모델 - 소켓**
- 틀징 : 네트워크 상에서 프로세스간 통신, local&remote 통신가능


**2.공유 메모리**
- 특징 : ipc를 위해 __공유 메모리 영역__ 을 구축하고, 공유 영역을 통해 자원이나 데이터를 주고 받는다.
- 장점 : 커널 의존성이 낮기 때문에 __속도가 빠르다__ , 유저 레벨에서 ipc가 가능하기 때문에, __통신이 자유롭다__
- 단점 : 자원과 데이터를 __공유하기 때문에 동기화!!!__ 이슈 발생.



## 32bit CPU와 64bit CPU의 차이

bit : CPU가 처리하는 데이터의 최소 단위(레지스터)의 크기
	- 32bit/64bit CPU는 한 번에 다룰 수 있는 데이터의 최대 크기가 32bit/64bit
- CPU 내부 부품은 비트를 기준으로 제작된다.
	- 32bit CPU 내의 레지스터 크기, 산술 논리 연산장치, 버스의 크기, 대역폭 모두 32bit
- 메모리 주소 레지스터(MAR, 메모리 주소를 지정하는 레지스터) 크기가 32bit 이므로 표현 할 수 있는 메모리 주소의 범위가 0~2의32승, 총 크기는 2의32승bit, 약 4GB이다

**차이점**
- 32bit CPU컴퓨터는 최대 4GB의 메모리까지만 사용 가능하다
- 64bit CPU컴퓨터는 4GB이상의 메인 메모리를 사용가능


## 장기/단기/중기 스케줄러에 대해 설명해라
![스케줄라](https://user-images.githubusercontent.com/55946791/81558928-80fd1280-93c9-11ea-9c86-f50c267ec647.jpg)


**장기 스케줄러(잡 스케줄러)**
- 메모리와 디스크 사이에서 메모리에(Ready Queue)에 어떤 걸 집어넣을지 결정
- 하드디스크에서 메인 메모리로 로드하는것은 꽤 느린 작업이므로, 장기 스케줄러는 신중히 프로세스를 로드해야한다.
- 입/출력을 많이하는 프로세스&cpu연산을 많이 하는 프로세스를 적절히 선택하여 메인 메모리로 로드하는 것이 중요
- 하드디스크 -> 메인 메모리

**단기 스케줄러(cpu 스케줄러)**
- CPU와 메모리 사이에서 Ready Queue에 있는 프로세스 중 어떤 것을 CPU 할당을 받게 할지 스케줄링
- 메인 메모리  -> CPU

**중기 스케줄러(Swapper)**
- 여유공간 부족 시 공간을 만들기 위해 메모리에서 쫓아내어 디스크로 옮김, 동시에 메모리가 많이 올라가는 것을 조절

>[참고1](https://twinw.tistory.com/4)
>[참고2](https://twinjh.tistory.com/18)

## 멀티프로세스와 멀티쓰레드는 무엇이고 어떤 차이가 있나요
- 멀티프로세스 : 여러개의 프로세서를 이용해 여러개의 프로세스로 작업하는것
	- 문맥 교환시 오버헤드가 크다
	- 프로세스간 통신이 어렵다
	- 프로세스간 독립적이다
- 멀티쓰레드 : 하나의 프로세서로 여러개의 쓰레드로 작업하는것
	- 스레드간 자원을 공유하기 때문에
	- 문맥교환시 오버헤드가 적고, 스레드간 통신이 비교적 쉽고, 중복되는 자원을 줄일수있다
	- 하지만, 동기화에 신경써야 하고 , 하나의 스레드에 문제가 생기면 전체 스레드에 문제가 발생한다.

## 사용자 수준 쓰레드와 커널 수준 쓰레드란 무엇인가요

**사용자 수준 스레드**

- 장점
	- 스레드 전환 시 커널 스케줄러를 호출할 필요가 없기 때문에
	- 사용자 수준 스레드는 context swith가 없다.
	- 따라서 커널 수준 스레드 보다 오버헤드가 작다
	- 스레드 스케줄러가 사용자 모드에만 존재한다
- 단점
	- 프로세스 내의 한 스레드가 커널로 진입하는 순간 나머지 스레드는 전부 정지된다
	- 이는 커널이 스레드의 존재를 알지 못하기 때문에 발생하는 현상

**커널 수준 스레드**

-장점
	- 사용자 수준 스레드 보다 효율적이다
	- 커널 스레드를 쓰면 멀티프로세서를 활용할 수 잇는 장점이있다.
	- 사용자 스레드 cpu가 아무리 암ㅎ더라도 커널 모드의 스케줄이 되지 않으므로 cpu에 효율적으로 스레드를 배당할 수 없다
-단점
	- 커널 스케줄러를 통해 context swith가 발생한다
	- 이 과정에서 프로세서 모드가 사용자 모드와 커널 모드 사이를 움직이기 때문에 빈번할 수록 성능 하락

>[참고](https://geekhub.tistory.com/58)

## 동기화란 무엇이며 어떤 해결방법이 있나요
- 동기화
	- 공유 자원에 대하여 동시에 접근하는 프로세스/스레드 들로 인해 발생하는 문제를 해결하기 위해 행하는 방식

- 경쟁 상태 (Race Condition) :
	경쟁 상태란 두 개 이상의 프로세스 혹은 스레드가 공유 자원을 동시에 사용할 때 그 순서에 따라 결과가 달라지는 문제.
	은행 잔고를 예제로 들면 은행 잔고라는 공유 데이터를 읽어와서 입금 연산과 출금 연산을 하는데, 동시에 접근해서 연산해버리면 한 쪽 연산이 반영이 안되는 문제

- 임계영역과 크리티컬 섹션 :
	사전상으로는 같은 말이지만, 의미하는 바가 다를 수 있다.
	임계영역은 프로세스간 자원이 공유될 수 있는 코드 블록을 의미하며, 크리티컬 섹션은 하나의 동기화 방법을 말한다. 임계 영역을 프로세스들이 같이 쓸 수 있는 전제 조건은 다음과 같다.

	- 상호 배제 (Mutal Exculsion) : 프로세스가 크리티컬 섹션에 들어가 있다면, 다른 프로세스는 크리티컬 섹션에 들어갈 수 없다.
	- 진행 (Progress) : 크리티컬 섹션에 들어가 있는 프로세스가 없다면 다른 후보 프로세스가 진입할 수 있다.
	한정된 대기 (Bounded Waiting) : 프로세스가 진입 가능한 횟수에는 제한이 있다(특정한 한 프로세스만 계속 진입하는 것을 방지).

- Lock :
	하드웨어 기반 처리로, 임계 영역에 진입하기 위해서는 Lock이 필요하다. 임계 영역에 들어가는 프로세스는 Lock을 획득하고, 빠져나올때 Lock을 반납한다. 다중 처리기 환경에서 성능을 보장할 수 없다.
<br>

**세마포어**

- 바쁜대기 해결
- 연산 방법 :

```
- P : 검사(Proberen), 프로세스를 대기시키는 'wait 동작'으로 임계영역에 진입하기 위한 연산
- P(S) : while S <= O do no-op;

- S := S - ;

- V : 증가(Verhogen), 대기 중인 프로세스를 '깨우는 신호를' 보내는 signal 동작으로 임계영역에 나오기 위한 연산
- V(S) : S := S + 1;
```

- 문제점 :
	- 1. p나v 실행 안되면 , 데드락 발생
	- 2. v실행후 2개이상의 프로세스 동시 접근시, 상호배제 보장x

- 종류 : OS는 카운팅/이진 세마포어를 구분한다.
		- 카운팅 세마포어 : 동시에 사용가능한 자원에 대해 사용되며, 임계영역 안에 스레드나 프로세스가 들어오면 카운트를 증가시켜, 일정 숫자만큼의 스레드만 사용하게 하는 것
		- 이진 세마포어 : 0과 1로만 된 세마포어로, 임계영역 안에 하나의 프로세스만 들어갈 수 있다. 뮤텍스라고도 함.


**모니터**
	- 락을 얻고 해제하는 부분이 자동으로 된다는 점만 빼고는 거의 세마포어와 비슷하다.


**Busy Waiting**
				- 멀티 쓰레드 환경에서, 공유자원을 사용할때 기다리는 쓰레드가 __공유 자원을 사용할수 있는지 계속해서 무한 루프를 돌면서 조건문을 체크하는__ 방식
				- 임계 영역에 진입하려는 프로세스는 계속해서 진입하는 코드를 실행해야 한다. 따라서 성능의 저하가 발생할 수 있음.
			- 세마포어에서도 데드락이 발생할 수 있다.

## 멀티프로세싱, 멀티프로그래밍, 멀티스레딩, 멀티태스킹
- CPU 코어의 관점에서 생각

**멀티 프로세싱**
 - CPU N 프로세스 N 수행 (멀티 프로세스X, 멀티 프로세서O)

**멀티 쓰레딩**
 - CPU 1, 쓰레드 N 수행

**멀티 프로그래밍**
 - CPU 1 프로세스 N 수행
 - 프로세스 A에 대해서 프로세서가 작업(ex io작업)을 처리할때 낭비되는 시간동안 다른 프로세스를 처리하도록 하는 것 입니다.
 - __CPU의 자원이 낭비되는 것을 최소화__

**멀티 태스킹**
	- 다수의 TASK(프로세스보다 조금더 확장된 개념)를 운영체제의 스케줄링에 의해 번갈아가면서 수행하는것
	- __일정하게 정해진 시간동안 번갈아가면서 각각의 Task를 처리하는 것__
	- job > task > thread, 여러 스레드가 모인것이 태스크


## 톰캣은 멀티 프로세스인가 멀티 스레드인가
- WAS

## 아파치는 멀티 프로세스인가 멀티 스레드인가
- WS

## 동기, 비동기, 블로킹, 넌블로킹 차이

**동기**
- 어떤 일에 대한 요청과 응답(혹은 입출력)이 __동시에 이루어져야__ 하는 것
- call하고 응답이 올 때까지 기다렸다가 다음 로직을 실행한다.
* 장점 : 안전성이 보장된다. 순서가 보장된다.
* 단점 : 느리다.

**비동기**
- 어떤 일에 대한 요청과 응답이 __동시에 이루어질 필요 없이__ 따로 이루어지는 것.
-  call하고 응답이 오지 않아도 다음 로직을 실행한다.
* 장점 : 빠르다
* 단점 : 처리 하기가 까다롭다. 순서가 보장이 되지 않는다.


**블로킹**
- 어떤 요청에 대한 __응답이 올 때까지 대기__ 하는 것.
- 즉 동기를 위해서는 블로킹 되어야 함

**넌블로킹**
- 어떤 요청에 대해서 응답을 대기하지 않고 계속 루틴을 수행하는 것.
- 비동기를 위해서는 넌블로킹 되어야 하지만, 넌블로킹이 비동기는 아니다(포함관계라고 생각하면 될 듯)
- 예를 들어 넌블로킹이면서, 요청에 대한 응답을 계속해서 요구하는 폴링 방식의 경우, 비동기라 보기는 힘들다.
- 이벤트 핸들러나 인터럽트를 통해 응답을 받는 것이 비동기 모델.

### 스레드와 프로세스의 차이

|프로세스|스레드|
|--|--|
|요리작업전체 | 각각의 조리|
|os입장에서 작업단위 | cpu입장에서 작업단위|
| 프로세스간 약하게 연결 | 스레드간 강하게 연결|
| 프로세스간 독립적 | 코드, 데이터, 힙 영역 공유|

**프로세스**
![process](https://user-images.githubusercontent.com/55946791/81820714-ed177c00-956b-11ea-8abb-59bff294c65a.png)

- 프로그램이 메모리에 올라와 OS로부터 자원을 할당받은 것
- 다른 프로세스 __메모리에 직접 접근 불가__ (공유메모리나 커널을이용해서 메시지전달 )

- __문맥교환__ : cpu에서 여러 프로세스를 돌아가면서 작업을 처리하는 과정(현재 프로세스상태 보관, 다음 프로세스상태 복구하는 작업)

**스레드**
![thread](https://user-images.githubusercontent.com/55946791/81820709-ebe64f00-956b-11ea-828d-36b063c1fced.png)
-  프로세스 내에서 실행되는 흐름의 단위를 말한다
-  프로세스 내에서 스레드끼리 주소공간이나 자원들을 공유하면서 실행 (code, data, heap 공유)
- 장점 :
	- 불필요한 __자원 중복 없앤다__ : 시스템 효율 향상
	- 프로세스간 통신보다 스레드간 __통신이 쉽다__
	- 자원을 공유하므로 문맥교환시 오버헤드가 적다

- 단점
 	- 자원을 공유하므로 __동기화__ 에 유의해야한다.
	- 한 스레드에 문제가 생기면 전체 프로세스에 영향(익스플로러는 문제 생기면 모두종료 / 크롬은 멀티프로세스여서 모두 종료x)

>[참고](https://gmlwjd9405.github.io/2018/09/14/process-vs-thread.html)
